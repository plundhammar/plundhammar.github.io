<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on plundhammar</title>
    <link>https://plundhammar.github.io/posts/</link>
    <description>Recent content in Posts on plundhammar</description>
    <generator>Hugo -- 0.134.3</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Sep 2024 16:02:27 +0200</lastBuildDate>
    <atom:link href="https://plundhammar.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Sequential Neural Networks</title>
      <link>https://plundhammar.github.io/posts/sequential_networks/</link>
      <pubDate>Fri, 27 Sep 2024 16:02:27 +0200</pubDate>
      <guid>https://plundhammar.github.io/posts/sequential_networks/</guid>
      <description>&lt;p&gt;&lt;strong&gt;This is a preliminary, hands-on, and maybe useful walk-trough of a sequential neural network in PyTorch. This is a summary of some notes I have been taking while reading about different topics in machine learning, see Refs. [1-3].&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Suppose one has data that consists of an independent vector $\mathbf{x}$ and a dependent vector $\mathbf{y}$ such that $\mathbf{y} = f(\mathbf{x})$ for some function $f$. Let say we knew the set $(\mathbf{x}, \mathbf{y})$ then we could guess what the function $f$ is. If vector $\mathbf{x}$ contains the entire domain of $f$ then we are done, but if $\mathbf{x}$ only contains part of the domain then the problem of estimating $f$ becomes more elusive. Let $\widehat{f}$ denote an estimation of $f$.&lt;/p&gt;</description>
    </item>
    <item>
      <title>`Compton_MLEM`, A GPU-Based Image Reconstruction Application in CUDA</title>
      <link>https://plundhammar.github.io/posts/compton_mlem-a-gpu-based-image-reconstruction-application-in-cuda/</link>
      <pubDate>Fri, 26 Jul 2024 00:40:04 -0900</pubDate>
      <guid>https://plundhammar.github.io/posts/compton_mlem-a-gpu-based-image-reconstruction-application-in-cuda/</guid>
      <description>&lt;p&gt;&lt;strong&gt;In this post I want to try to reconstruct an image from the simulated data in the previous post. Supposedly the original source consists of two point sources close together around z= -0.5 cm. However, I found it hard to understand the properties of the reconstruction. I will need to redo this simulation with full a priori information about the simulated source.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;So, I have looked into the reconstruction application &lt;code&gt;Compton_MLEM&lt;/code&gt; by Matt Leigh, Ref. [1]. It is written in CUDA Ref. [2], an extension of the C programming language with the ability to specify thread-level parallelism in C. This programming language was new to me, and I had a hard time simply trying to install the necessary software to make everything work (especially the nividia drivers caused me some headache)! I recommend doing the tutorial in Ref. [3] just to get a feeling for the language, and to demystify it. It is very similar to C++, but with some additional methods to parallelize the calculations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Properties of List-Mode data from a Compton Camera</title>
      <link>https://plundhammar.github.io/posts/properties-of-list-mode-data-of-a-compton-camera/</link>
      <pubDate>Fri, 26 Jul 2024 00:40:04 -0800</pubDate>
      <guid>https://plundhammar.github.io/posts/properties-of-list-mode-data-of-a-compton-camera/</guid>
      <description>&lt;p&gt;&lt;strong&gt;The energies of a Compton scatter chain are correlated through the Compton scattering equation as well as the Klein-Nishina distribution. This means that some vital statistics must exist, and perhaps be possible to calculate in closed expression. In this post I wanted to give it a try and compare it to some simulated data.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I recently got a hold on some simulated list-mode data of photons interacting with a silicon volume. That is, a list
$$
[\mathbf{r}_1,E_1,\mathbf{r}_2,E_2]
$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding the System Matrix and the LM-MLEM Algorithm</title>
      <link>https://plundhammar.github.io/posts/understanding-the-system-matrix-and-the-lm-mlem-algorithm/</link>
      <pubDate>Fri, 26 Jul 2024 00:40:04 -0700</pubDate>
      <guid>https://plundhammar.github.io/posts/understanding-the-system-matrix-and-the-lm-mlem-algorithm/</guid>
      <description>&lt;p&gt;&lt;strong&gt;The List-Mode Maximum Likelihood Expectation Maximization (LM-MLEM) algorithm is widely used in Compton camera reconstruction. It&amp;rsquo;s well suited for the list-mode data architecture and easy to parallelize. This post will be somewhat technical and a sort of summary of the main arguments found in the litterature.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The problem has been stated many times, Ref.[1-8]. I will state it as follows (I will use the same notation as in Ref.[8]), and the proof of it will be the subject of a future post:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deconvolution and the System Matrix</title>
      <link>https://plundhammar.github.io/posts/deconvolution-and-system-matrices/</link>
      <pubDate>Fri, 19 Jul 2024 00:40:04 -0700</pubDate>
      <guid>https://plundhammar.github.io/posts/deconvolution-and-system-matrices/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Delving into the practicalities of the inverse problem of reconstructing Compton camera images will lead you to Legandre polynomials or Maximum Likelihood methods, most likely.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Since last week I have been interested in both the analytical reconstruction techniques as well as some of the iterative methods.&lt;/p&gt;
&lt;p&gt;Regarding iterative methods, what I found is that it is difficult to get a feeling on how the iterative methods properly work simply because the algorithms (I write mine in Python) is increadibly slow. However, I have made some progress and have been able to reproduce some results but in a very corse voxel space. One way of simplifying things is to simplify the system matrix. I was reading Ref. [1] where they sort of reduce the forward problem to the following statement:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cone-Surface Projections</title>
      <link>https://plundhammar.github.io/posts/cone-surface-projection-in-practice/</link>
      <pubDate>Fri, 12 Jul 2024 00:40:04 -0700</pubDate>
      <guid>https://plundhammar.github.io/posts/cone-surface-projection-in-practice/</guid>
      <description>&lt;p&gt;&lt;strong&gt;One of the first properties encountered in Compton camera image reconstruction is the cone-surface projection. Understandig the properties of this geometrical object will set the ground works for understanding more advanced models.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I was reading some articles of the early versions of the Compton camera image reconstruction procedure when I came across Ref.[1] talking about the &lt;em&gt;cone-surface projections&lt;/em&gt;. They investigated a primitive version of a &amp;lsquo;&amp;lsquo;Compton camera&amp;rsquo;&amp;rsquo;. Well, it kind of had some properties like a Compton camera like a scatterer and an absorber but they assumed that photons only scatter at a fixed given angle. This camera measures the cone-surface projection of a source. What this means is that the intensity measured at a given detector is proportional to the integral over the intersection of the cone and the source, given that the source is homogeneous.Â  Specifically, let $f(\mathbf{x})$ denote the source distribution, $\mathbf{k}$ the cone axis making angle $\beta$ with $\mathbf{n}$ along the cone surface, they defined&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
